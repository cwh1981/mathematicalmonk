---
layout: default
---
<div class="row">
  <div class="col-sm-12 col-md-6">
    <div class="well-sm">
      <h3>Introduction</h3>
      <p>이 페이지는 Mathematical Monk ML을 정리한 문서입니다. 관련 동영상이 궁금하신 분들은 아래 버튼을 눌러시면 됩니다.</p>
      <p>	
      <a href="https://www.youtube.com/watch?v=yDLKJtOVx5c&list=PLD0F06AA0D2E8FFBA" target="_blank">
	        <button type="button" class="btn btn-success">YouTube</button>
	      </a>
      </p>
    </div>

    <div class="well-sm">
      <h3>New Posts</h3>
      <ul class="post-list">
	      {% for post in site.posts limit:3 %}
	      <li>
	        <h4>
            <a href="{{ post.url | prepend: site.baseurl }}">{{ post.title }}</a>
	        </h4>
	        <p><span class="post-date">{{ post.date | date: "%b %-d, %Y" }}</span></p>
	        {{ post.excerpt }}
          <hr/>          
	      </li>
	      {% endfor %}
      </ul>
    </div>
  </div>
  
  <div class="col-sm-12 col-md-6">
    <div class="well-sm">
      <h3>Chapter 1</h3>
      <ul>
        <li><a href="{{ site.baseurl }}/docs/chapter01/0">(ML 1.1) Machine learning - overview and applications</a></li>
        <li><a href="{{ site.baseurl }}/docs/chapter01/1">(ML 1.2) What is supervised learning?</a></li>
        <li><a href="{{ site.baseurl }}/docs/chapter01/2">(ML 1.3) What is unsupervised learning?</a></li>
        <li><a href="{{ site.baseurl }}/docs/chapter01/3">(ML 1.4) Variations on supervised and unsupervised</a></li>
        <li><a href="{{ site.baseurl }}/docs/chapter01/4">(ML 1.5) Generative vs discriminative models</a></li>
        <li><a href="{{ site.baseurl }}/docs/chapter01/5">(ML 1.6) k-Nearest Neighbor classification algorithm</a></li>
      </ul>
    </div>
    <div class="well-sm">
      <h3>Chapter 2</h3>
      <ul>
        <li><a href="{{ site.baseurl }}/docs/chapter02/0">(ML 2.1) Classification trees (CART)</a></li>
        <li><a href="{{ site.baseurl }}/docs/chapter02/1">(ML 2.2) Regression trees (CART)</a></li>
        <li><a href="{{ site.baseurl }}/docs/chapter02/2">(ML 2.3) Growing a regression tree (CART)</a></li>
        <li><a href="{{ site.baseurl }}/docs/chapter02/3_1">(ML 2.4) Growing a classification tree (CART)</a></li>
        <li><a href="{{ site.baseurl }}/docs/chapter02/3_2">(ML 2.5) Generalizations for trees (CART)</a></li>
        <li><a href="{{ site.baseurl }}/docs/chapter02/3_3">(ML 2.6) Bootstrap aggregation (Bagging)</a></li>      
        <li><a href="{{ site.baseurl }}/docs/chapter02/4">(ML 2.7) Bagging for classification</a></li>
        <li><a href="{{ site.baseurl }}/docs/chapter02/5">(ML 2.8) Random forests</a></li>
      </ul>
    </div>
    <div class="well-sm">
      <h3>Chapter 3</h3>
      <ul>
        <li><a href="{{ site.baseurl }}/docs/chapter03/0">(ML 3.1) Decision theory (Basic Framework)</a></li>
        <li><a href="{{ site.baseurl }}/docs/chapter03/1">(ML 3.2) Minimizing conditional expected loss</a></li>
        <li><a href="{{ site.baseurl }}/docs/chapter03/2">(ML 3.3) Choosing f to minimize expected loss</a></li>
        <li><a href="{{ site.baseurl }}/docs/chapter03/3">(ML 3.4) Square loss</a></li>
        <li><a href="{{ site.baseurl }}/docs/chapter03/4">(ML 3.5) The Big Picture (part 1)</a></li>
        <li><a href="{{ site.baseurl }}/docs/chapter03/5">(ML 3.6) The Big Picture (part 2)</a></li>
        <li><a href="{{ site.baseurl }}/docs/chapter03/6">(ML 3.7) The Big Picture (part 3)</a></li>
      </ul>
    </div>

  </div>
</div>



